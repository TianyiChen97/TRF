{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Install GPAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install gpar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gpar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import iv\n",
    "from scipy.optimize import fsolve\n",
    "\n",
    "from gpar.regression import GPARRegressor\n",
    "from scipy.stats import vonmises\n",
    "from scipy import stats\n",
    "from scipy.stats import entropy\n",
    "from scipy import interpolate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Define Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions below compute fits and pdf of Vonmises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vonmises_density(x,mu,kappa):\n",
    "    \"\"\"\n",
    "    Calculate the von Mises density for a series x (a 1D numpy.array).\n",
    "    Input : \n",
    "        x : a 1D numpy.array of size L\n",
    "        mu : a 1D numpy.array of size n, the mean of the von Mises distributions\n",
    "        kappa : a 1D numpy.array of size n, the dispersion of the von Mises distributions\n",
    "    Output : \n",
    "        a (L x n) numpy array, L is the length of the series, and n is the size of the array containing the parameters. Each row of the output corresponds to a density\n",
    "    \"\"\"\n",
    "    res = []\n",
    "    for i in x:\n",
    "        f = np.exp(kappa*np.cos(i-mu))\n",
    "        n = 2*np.pi*iv(0,kappa)\n",
    "        res.append(f/n)\n",
    "    return(np.array(res))\n",
    "\n",
    "def vonmises_pdfit(series):\n",
    "    \"\"\"\n",
    "    Calculate the estimator of the mean and deviation of a sample, for a von Mises distribution\n",
    "    Input : \n",
    "        series : a 1D numpy.array\n",
    "    Output : \n",
    "        the estimators of the parameters mu and kappa of a von Mises distribution, in an list [mu, kappa]\n",
    "    \"\"\"\n",
    "    s0 = np.mean(np.sin(series))\n",
    "    c0 = np.mean(np.cos(series))\n",
    "    mu = np.arctan2(s0,c0)\n",
    "    var = 1-np.sqrt(s0**2+c0**2)\n",
    "    k = lambda kappa: 1-iv(1,kappa)/iv(0,kappa)-var\n",
    "    kappa = fsolve(k, 0.0)[0]\n",
    "    return([mu,kappa])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function below computes KL divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is the function to define KL divergence\n",
    "# Note: the samplepdf and observationpdf is the probability density function, not the sample count.\n",
    "def kldiver(samplepdf, observationpdf):\n",
    "    print(\"\\nIndividual Entropy\\n\")\n",
    "    print(entropy(samplepdf))\n",
    "    print(entropy(observationpdf))\n",
    "\n",
    "    print(\"\\nPairwise Kullback Leibler divergence\\n\")\n",
    "    firstkl = entropy(samplepdf, qk=observationpdf)\n",
    "    secondkl = entropy(observationpdf, qk=samplepdf)\n",
    "    print(firstkl)\n",
    "    print(secondkl)\n",
    "    return (firstkl,secondkl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function below computes inverse sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invcdf(vals, pdf, num_sam):\n",
    "    # Normalize\n",
    "    normalize = pdf/np.sum(pdf)\n",
    "    p = np.cumsum(normalize)\n",
    "    # define inverse function\n",
    "    inv_cdf = interpolate.interp1d(p,vals,bounds_error=False, fill_value = (-math.pi, math.pi))\n",
    "    # get number of data\n",
    "    r = np.random.rand(num_sam)\n",
    "    # get sample\n",
    "    sample = inv_cdf(r)\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function below compute MSE and MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is the function to define the MSE and MAE\n",
    "def countdiff(bins, sample, observation):\n",
    "    if len(observation) != len(sample):\n",
    "        print(\"Please generate the same length data\")\n",
    "    length = len(observation)\n",
    "    sumup = 0\n",
    "    sumup2 = 0\n",
    "    # counts and divisions in the real data\n",
    "    count,division = np.histogram(listall,range=(-math.pi,math.pi),bins=bins)\n",
    "    # change the sample to numpy array, note: if it is already np array, comment it out\n",
    "    s = sample\n",
    "    # compute MSE\n",
    "    for j in range(len(count)):\n",
    "        modelCount = s[(division[j] < s) & (s < division[j+1])].size\n",
    "        sumup += np.square(count[j] - modelCount)\n",
    "        sumup2+= np.abs(count[j] - modelCount)\n",
    "    mse = sumup/bins\n",
    "    mae = sumup2/bins\n",
    "    print('The MSE is ' + str(mse))\n",
    "    print('The MAE is ' + str(mae))\n",
    "    return mse, mae "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function below compute MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is the function to define the MSE\n",
    "def countdiffmse(bins, sample, observation):\n",
    "    length = len(observation)\n",
    "    sumup = 0\n",
    "    sumup2 = 0\n",
    "    # counts and divisions in the real data\n",
    "    count,division = np.histogram(listall,range=(-math.pi,math.pi),bins=bins)\n",
    "    # change the sample to numpy array, note: if it is already np array, comment it out\n",
    "    s = sample\n",
    "    # compute MSE\n",
    "    for j in range(len(count)):\n",
    "        modelCount = s[(division[j] < s) & (s < division[j+1])].size\n",
    "        sumup += np.square(count[j] - modelCount)\n",
    "        sumup2+= np.abs(count[j] - modelCount)\n",
    "    mse = sumup/bins\n",
    "    mae = sumup2/bins\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function below compute MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is the function to define the MAE\n",
    "def countdiffmae(bins, sample, observation):\n",
    "    length = len(observation)\n",
    "    sumup = 0\n",
    "    sumup2 = 0\n",
    "    # counts and divisions in the real data\n",
    "    count,division = np.histogram(listall,range=(-math.pi,math.pi),bins=bins)\n",
    "    # change the sample to numpy array, note: if it is already np array, comment it out\n",
    "    s = sample\n",
    "    # compute MSE\n",
    "    for j in range(len(count)):\n",
    "        modelCount = s[(division[j] < s) & (s < division[j+1])].size\n",
    "        sumup += np.square(count[j] - modelCount)\n",
    "        sumup2+= np.abs(count[j] - modelCount)\n",
    "    mse = sumup/bins\n",
    "    mae = sumup2/bins\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function Below compute average KL divergence of both way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is the function to define KL divergence\n",
    "# Note: the samplepdf and observationpdf is the probability density function, not the sample count.\n",
    "\n",
    "def kldiver2(samplepdf, observationpdf):\n",
    "    #print(\"\\nIndividual Entropy\\n\")\n",
    "    #print(entropy(samplepdf))\n",
    "    #print(entropy(observationpdf))\n",
    "\n",
    "    #print(\"\\nPairwise Kullback Leibler divergence\\n\")\n",
    "    firstkl = entropy(samplepdf, qk=observationpdf)\n",
    "    secondkl = entropy(observationpdf, qk=samplepdf)\n",
    "    #print(firstkl)\n",
    "    #print(secondkl)\n",
    "    #return (firstkl,secondkl)\n",
    "    return (firstkl+secondkl)/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/idies/workspace/Storage/Genius/TRF/FinalData/Data_June17.csv\")\n",
    "df = df.drop(columns=[\"Unnamed: 0\"])\n",
    "df = df.drop(columns=[\"Unnamed: 0.1\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert Time String to make sure it will be in format (HH:MM:SS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = []\n",
    "end = []\n",
    "for i in range(len(df['start_time'])):\n",
    "    if len(df['start_time'][i]) < 8:\n",
    "        start.append('0' + df['start_time'][i])\n",
    "    else:\n",
    "        start.append(df['start_time'][i])\n",
    "    \n",
    "    if len(df['end_time'][i]) < 8:\n",
    "        end.append('0' + df['end_time'][i])\n",
    "    else:\n",
    "        end.append(df['end_time'][i])\n",
    "df['start_time'] = start\n",
    "df['end_time'] = end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert time string in integer value 0 - 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_start = []\n",
    "convert_end = []\n",
    "for i in range(0,len(df[\"end_time\"])):\n",
    "    convert_start.append(int(df[\"start_time\"][i][0:2]) + int(df[\"start_time\"][i][3:5])/60 + int(df[\"start_time\"][i][6:])/3600)\n",
    "    convert_end.append(int(df[\"end_time\"][i][0:2]) + int(df[\"end_time\"][i][3:5])/60 + int(df[\"end_time\"][i][6:])/3600)\n",
    "df[\"starthour\"] = convert_start\n",
    "df[\"endhour\"] = convert_end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert time into $-\\pi$ to $\\pi$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df[(df[\"name.s\"] == \"Sleep\")]\n",
    "wake = df3[\"endhour\"] * math.pi /12 - math.pi\n",
    "sleep = df3[\"starthour\"] * math.pi /12 - math.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[(df[\"name.s\"] == \"Food\")]\n",
    "d = df2[(df2[\"mealsize.s\"] == \"drinkOnly\")][\"starthour\"] * math.pi /12 - math.pi\n",
    "lm = df2[(df2[\"mealsize.s\"] == \"largeMeal\")][\"starthour\"] * math.pi /12 - math.pi\n",
    "ls = df2[(df2[\"mealsize.s\"] == \"largeSnack\")][\"starthour\"] * math.pi /12 - math.pi\n",
    "m = df2[(df2[\"mealsize.s\"] == \"mediumMeal\")][\"starthour\"] * math.pi /12 - math.pi\n",
    "sm = df2[(df2[\"mealsize.s\"] == \"smallMeal\")][\"starthour\"] * math.pi /12 - math.pi\n",
    "ss = df2[(df2[\"mealsize.s\"] == \"smallSnack\")][\"starthour\"] * math.pi /12 - math.pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit each of different type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wake_val = vonmises_pdfit(wake)\n",
    "print(wake_val)\n",
    "sleep_val = vonmises_pdfit(sleep)\n",
    "print(sleep_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food1 = vonmises_pdfit(d)\n",
    "print(food1)\n",
    "food2 = vonmises_pdfit(lm)\n",
    "print(food2)\n",
    "food3 = vonmises_pdfit(ls)\n",
    "print(food3)\n",
    "food4 = vonmises_pdfit(m)\n",
    "print(food4)\n",
    "food5 = vonmises_pdfit(sm)\n",
    "print(food5)\n",
    "food6 = vonmises_pdfit(ss)\n",
    "print(food6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run GPAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create toy data set.\n",
    "n = 1000\n",
    "x = np.linspace(-math.pi, math.pi, n)\n",
    "noise = 0.05\n",
    "fmin = np.min([len(wake), len(sleep), len(ss), len(sm), len(m), len(ls), len(lm),len(d),200])\n",
    "\n",
    "# Draw functions depending on each other in complicated ways.\n",
    "# Wake\n",
    "f1 = vonmises_density(x,wake_val[0],wake_val[1])\n",
    "a1 = vonmises.rvs(wake_val[1],wake_val[0], size =fmin )\n",
    "# Food\n",
    "food_val_a1 = vonmises_pdfit(list(d) +list(a1))\n",
    "f2 = vonmises_density(x,food_val_a1[0],food_val_a1[1])\n",
    "a2 = vonmises.rvs(food_val_a1[1],food_val_a1[0], size = fmin)\n",
    "\n",
    "food_val_a2 = vonmises_pdfit(list(sm) +list(a2) + list(a1))\n",
    "f3 = vonmises_density(x,food_val_a2[0],food_val_a2[1])\n",
    "a3 = vonmises.rvs(food_val_a2[1],food_val_a2[0], size = fmin)\n",
    "\n",
    "food_val_a3 = vonmises_pdfit(list(ss) +list(a2) + list(a3))\n",
    "f4 = vonmises_density(x,food_val_a3[0],food_val_a3[1])\n",
    "a4 = vonmises.rvs(food_val_a3[1],food_val_a3[0], size = fmin)\n",
    "\n",
    "if food5[0] > food6[0]:\n",
    "    mval = list(a4)\n",
    "else:\n",
    "    mval = list(a3)\n",
    "\n",
    "food_val_a4 = vonmises_pdfit(list(m)+list(a2) + mval)\n",
    "f5 = vonmises_density(x,food_val_a4[0],food_val_a4[1])\n",
    "a5 = vonmises.rvs(food_val_a4[1],food_val_a4[0], size = fmin)\n",
    "\n",
    "food_val_a5 = vonmises_pdfit(list(ls)+list(a2) + list(a5))\n",
    "f6 = vonmises_density(x,food_val_a5[0],food_val_a5[1])\n",
    "a6 = vonmises.rvs(food_val_a5[1],food_val_a5[0], size = fmin)\n",
    "\n",
    "food_val_a6 = vonmises_pdfit(list(lm)+list(a2) + list(a5))\n",
    "f7 = vonmises_density(x,food_val_a6[0],food_val_a6[1])\n",
    "a7 = vonmises.rvs(food_val_a6[1],food_val_a6[0], size = fmin)\n",
    "\n",
    "# Sleep \n",
    "sleep_val_b = vonmises_pdfit(list(sleep) + list(a7) + list(a6))\n",
    "f8 = vonmises_density(x,sleep_val_b[0],sleep_val_b[1])\n",
    "\n",
    "f = np.stack((f1, f2, f3, f4, f5, f6, f7, f8), axis=0).T\n",
    "\n",
    "# Add noise and subsample.\n",
    "y = f + noise * np.random.randn(n, 8)\n",
    "x_obs, y_obs = x[::8], y[::8]\n",
    "\n",
    "# Fit and predict GPAR.\n",
    "model = GPARRegressor(scale=0.1,\n",
    "                      linear=False, #linear_scale=10.,\n",
    "                      nonlinear=True, nonlinear_scale=1,\n",
    "                      noise=0.05,\n",
    "                      impute=True, replace=True, normalise_y=False)\n",
    "model.fit(x_obs, y_obs)\n",
    "means, lowers, uppers = \\\n",
    "    model.predict(x, num_samples=200, credible_bounds=True, latent=True)\n",
    "\n",
    "# Fit and predict independent GPs: set markov=0.\n",
    "igp = GPARRegressor(scale=0.1,\n",
    "                    linear=False, #linear_scale=10.,\n",
    "                    nonlinear=True, nonlinear_scale=1,\n",
    "                    noise=0.05, markov=0, normalise_y=False)\n",
    "igp.fit(x_obs, y_obs)\n",
    "igp_means, igp_lowers, igp_uppers = \\\n",
    "    igp.predict(x, num_samples=200, credible_bounds=True, latent=True)\n",
    "\n",
    "# Plot the result.\n",
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "for i in range(8):\n",
    "    ax = plt.subplot(8, 1, i + 1)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    plt.scatter(x_obs, y_obs[:, i], label='Observations', c='black', s=15)\n",
    "    plt.plot(x, f[:, i], label='Truth', c='tab:orange')\n",
    "    plt.plot(x, means[:, i], label='GPAR', c='tab:blue')\n",
    "    plt.fill_between(x, lowers[:, i], uppers[:, i],\n",
    "                     facecolor='tab:blue', alpha=.25)\n",
    "    plt.plot(x, igp_means[:, i], label='IGP', c='tab:green')\n",
    "    plt.fill_between(x, igp_lowers[:, i], igp_uppers[:, i],\n",
    "                     facecolor='tab:green', alpha=.25)\n",
    "    plt.xlabel('$t$')\n",
    "    plt.ylabel('$y_{}$'.format(i + 1))\n",
    "    if i == 2:\n",
    "        leg = plt.legend(facecolor='#eeeeee')\n",
    "        leg.get_frame().set_linewidth(0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make one gigantic function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb = []\n",
    "for i in range(0, len(igp_means)):\n",
    "    comb.append(igp_means[:,0][i]/8 + igp_means[:,1][i]/8 + igp_means[:,2][i]/8 + igp_means[:,3][i]/8 + igp_means[:,4][i]/8 + igp_means[:,5][i]/8+ igp_means[:,6][i]/8+ igp_means[:,7][i]/8)\n",
    "    \n",
    "listall = list(wake) + list(sleep) + list(d) + list(ss) + list(sm) + list(m) + list(ls) + list(lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(listall,label='Actual data based kernel desnsity estimation')\n",
    "plt.plot(x, comb, label = 'GPAR')\n",
    "plt.hist(listall,density=True,label='Actual Data')\n",
    "plt.ylabel('Probability')\n",
    "plt.xlabel('Data')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute KL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the probability density function based on actual data\n",
    "actual_density = stats.kde.gaussian_kde(listall)\n",
    "actual_density = actual_density(x)\n",
    "kldiver(actual_density, comb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute MAE and MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "papermse = []\n",
    "papermae = []\n",
    "for i in range(1000):\n",
    "    samples = invcdf(x,comb, len(listall))\n",
    "    papermse.append(countdiffmse(48,samples, listall))\n",
    "    papermae.append(countdiffmae(48,samples, listall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanmse = np.mean(papermse)\n",
    "meanmae = np.mean(papermae)\n",
    "lowersmse = np.percentile(papermse, 2.5)\n",
    "uppersmse = np.percentile(papermse, 100 - 2.5)\n",
    "lowersmae = np.percentile(papermae, 2.5)\n",
    "uppersmae = np.percentile(papermae, 100 - 2.5)\n",
    "\n",
    "print(\"MSE mean is \" + str(meanmse))\n",
    "print(\"MSE lower is \" + str(lowersmse))\n",
    "print(\"MSE upper is \" + str(uppersmse))\n",
    "\n",
    "print(\"MAE mean is \" + str(meanmae))\n",
    "print(\"MAE lower is \" + str(lowersmae))\n",
    "print(\"MAE upper is \" + str(uppersmae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run with each individual\n",
    "- Because everyone has different number of meals, will combine all the food data and make a simple one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the bigger data set into subset of individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the Big Dataframe to smaller ones meaning each of the itmes\n",
    "a = [v for k, v in df.groupby('userid.s')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = []\n",
    "kl = []\n",
    "kl2=[]\n",
    "for i in range(0,len(a)):\n",
    "    print(i)\n",
    "    # Get Sleep and wake up time\n",
    "    df3a = a[i][(a[i][\"name.s\"] == \"Sleep\")]\n",
    "    # get wake time and sleep time\n",
    "    wakea = df3a[\"endhour\"] * math.pi /12 - math.pi\n",
    "    sleepa = df3a[\"starthour\"] * math.pi /12 - math.pi\n",
    "    # get food data\n",
    "    df2a = a[i][(a[i][\"name.s\"] == \"Food\")]\n",
    "    fooda = df2a[\"starthour\"] * math.pi /12 - math.pi\n",
    "    da = df2a[(df2a[\"mealsize.s\"] == \"drinkOnly\")][\"starthour\"] * math.pi /12 - math.pi\n",
    "    lma = df2a[(df2a[\"mealsize.s\"] == \"largeMeal\")][\"starthour\"] * math.pi /12 - math.pi\n",
    "    lsa = df2a[(df2a[\"mealsize.s\"] == \"largeSnack\")][\"starthour\"] * math.pi /12 - math.pi\n",
    "    ma = df2a[(df2a[\"mealsize.s\"] == \"mediumMeal\")][\"starthour\"] * math.pi /12 - math.pi\n",
    "    sma = df2a[(df2a[\"mealsize.s\"] == \"smallMeal\")][\"starthour\"] * math.pi /12 - math.pi\n",
    "    ssa = df2a[(df2a[\"mealsize.s\"] == \"smallSnack\")][\"starthour\"] * math.pi /12 - math.pi\n",
    "    \n",
    "    # Von-Mises Fit does not work well under 5 people\n",
    "    if (len(wakea) >= 5 and len(da) >= 5 and len(lma) >= 5 and len(lsa) >= 5 and len(ma) >= 5 and len(sma) >= 5 and len(ssa) >= 5):\n",
    "        # Get User\n",
    "        user.append(np.unique(list(a[i]['userid.s']))[0])\n",
    "        \n",
    "        food1a = vonmises_pdfit(da)\n",
    "        food2a = vonmises_pdfit(lma)\n",
    "        food3a = vonmises_pdfit(lsa)\n",
    "        food4a = vonmises_pdfit(ma)\n",
    "        food5a = vonmises_pdfit(sma)\n",
    "        food6a = vonmises_pdfit(ssa)\n",
    "        \n",
    "        n = 1000\n",
    "        x = np.linspace(-math.pi, math.pi, n)\n",
    "        noise = 0.05\n",
    "        fmin = np.min([len(wakea), len(sleepa), len(ssa), len(sma), len(ma), len(lsa), len(lma),len(da),200])\n",
    "\n",
    "        # Draw functions depending on each other in complicated ways.\n",
    "        # Wake\n",
    "        wake_vala = vonmises_pdfit(wakea)\n",
    "        f1a = vonmises_density(x,wake_vala[0],wake_vala[1])\n",
    "        a1a = vonmises.rvs(wake_vala[1],wake_vala[0], size =fmin)\n",
    "        # Food\n",
    "\n",
    "        food_val_a1a = vonmises_pdfit(list(da) +list(a1a))\n",
    "        f2a = vonmises_density(x,food_val_a1a[0],food_val_a1a[1])\n",
    "        a2a = vonmises.rvs(food_val_a1a[1],food_val_a1a[0], size = fmin)\n",
    "\n",
    "        food_val_a2a = vonmises_pdfit(list(sma) +list(a2a) + list(a1a))\n",
    "        f3a = vonmises_density(x,food_val_a2a[0],food_val_a2a[1])\n",
    "        a3a = vonmises.rvs(food_val_a2a[1],food_val_a2a[0], size = fmin)\n",
    "\n",
    "        food_val_a3a = vonmises_pdfit(list(ssa) +list(a2a) + list(a3a))\n",
    "        f4a = vonmises_density(x,food_val_a3a[0],food_val_a3a[1])\n",
    "        a4a = vonmises.rvs(food_val_a3a[1],food_val_a3a[0], size = fmin)\n",
    "\n",
    "        if food5a[0] > food6a[0]:\n",
    "            mval = list(a4a)\n",
    "        else:\n",
    "            mval = list(a3a)\n",
    "\n",
    "        food_val_a4a = vonmises_pdfit(list(ma)+list(a2a) + mval)\n",
    "        f5a = vonmises_density(x,food_val_a4a[0],food_val_a4a[1])\n",
    "        a5a = vonmises.rvs(food_val_a4a[1],food_val_a4a[0], size = fmin)\n",
    "\n",
    "        food_val_a5a = vonmises_pdfit(list(lsa)+list(a2a) + list(a5a))\n",
    "        f6a = vonmises_density(x,food_val_a5a[0],food_val_a5a[1])\n",
    "        a6a = vonmises.rvs(food_val_a5a[1],food_val_a5a[0], size = fmin)\n",
    "\n",
    "        food_val_a6a = vonmises_pdfit(list(lma)+list(a2a) + list(a5a))\n",
    "        f7a = vonmises_density(x,food_val_a6a[0],food_val_a6a[1])\n",
    "        a7a = vonmises.rvs(food_val_a6a[1],food_val_a6a[0], size = fmin)\n",
    "\n",
    "        # Sleep \n",
    "        sleep_val_ba = vonmises_pdfit(list(sleepa) + list(a7a) + list(a6a))\n",
    "        f8a = vonmises_density(x,sleep_val_ba[0],sleep_val_ba[1])\n",
    "        \n",
    "        fa = np.stack((f1a, f2a, f3a, f4a, f5a, f6a, f7a, f8a), axis=0).T\n",
    "        \n",
    "        # Add noise and subsample.\n",
    "        ya = fa + noise * np.random.randn(n, 8)\n",
    "        x_obs, y_obsa = x[::8], ya[::8]\n",
    "\n",
    "        # Fit and predict independent GPs: set markov=0.\n",
    "        igpa = GPARRegressor(scale=0.1,\n",
    "                            linear=False, #linear_scale=10.,\n",
    "                            nonlinear=True, nonlinear_scale=1,\n",
    "                            noise=0.05, markov=0, normalise_y=False)\n",
    "        igpa.fit(x_obs, y_obsa)\n",
    "        igp_meansa, igp_lowersa, igp_uppersa = \\\n",
    "            igpa.predict(x, num_samples=200, credible_bounds=True, latent=True)\n",
    "\n",
    "        comba = []\n",
    "        for j in range(0, len(igp_meansa)):\n",
    "            comba.append(igp_meansa[:,0][j]/8 + igp_meansa[:,1][j]/8 + igp_meansa[:,2][j]/8 + igp_meansa[:,3][j]/8 + igp_meansa[:,4][j]/8 + igp_meansa[:,5][j]/8 + igp_meansa[:,6][j]/8 + igp_meansa[:,7][j]/8)\n",
    "        # get KL divergence values\n",
    "        kl.append(kldiver2(comba, comb))\n",
    "        \n",
    "        listalla = list(wakea) + list(sleepa) + list(da) + list(ssa) + list(sma) + list(ma) + list(lsa) + list(lma)\n",
    "        # generate the probability density function based on actual data\n",
    "        actual_densitya = stats.kde.gaussian_kde(listalla)\n",
    "        actual_densitya = actual_densitya(x)\n",
    "        kl2.append(kldiver2(comba, actual_densitya))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = []\n",
    "kls = []\n",
    "final = {}\n",
    "for i in range(0, len(kl)):\n",
    "    users.append(user[i])\n",
    "    kls.append(kl[i])\n",
    "    final[user[i]] = kl[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfkl = pd.DataFrame(users,columns=['user'])\n",
    "dfkl[\"kl\"] = kls\n",
    "dfkl.to_csv(\"pop.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = []\n",
    "kls2 = []\n",
    "final = {}\n",
    "for i in range(0, len(kl2)):\n",
    "    users.append(user[i])\n",
    "    kls2.append(kl2[i])\n",
    "    final[user[i]] = kl2[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfkl2 = pd.DataFrame(users,columns=['user'])\n",
    "dfkl2[\"kl\"] = kls2\n",
    "dfkl2.to_csv(\"ind.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (py37)",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
